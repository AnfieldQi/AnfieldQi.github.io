<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python基础 on AnfieldQi`s Blog</title>
    <link>https://anfieldqi.github.io/categories/python%E5%9F%BA%E7%A1%80/</link>
    <description>Recent content in python基础 on AnfieldQi`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 07 May 2020 13:52:26 +0800</lastBuildDate>
    
	<atom:link href="https://anfieldqi.github.io/categories/python%E5%9F%BA%E7%A1%80/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Python_crawler</title>
      <link>https://anfieldqi.github.io/2020/python_crawler/</link>
      <pubDate>Thu, 07 May 2020 13:52:26 +0800</pubDate>
      
      <guid>https://anfieldqi.github.io/2020/python_crawler/</guid>
      <description>1. beautifulSoup 1.1 基础 #1.使用beautifulsoup解析html网页/读取a标签的链接 from bs4 import BeautifulSoup from urllib.request import urlopen html=urlopen(&amp;#34;https://baike.baidu.com/item/%E5%AE%81%E5%9F%8E%E9%AB%98%E7%BA%A7%E4%B8%AD%E5%AD%A6/9016318?fr=aladdin&amp;#34;).read().decode() print(html) #%% soup=BeautifulSoup(html,features=&amp;#34;lxml&amp;#34;) print(soup.h1) print(soup.div) #%% all_href=soup.find_all(&amp;#34;a&amp;#34;) for l in enumerate(all_href): if l[1].get(&amp;#39;href&amp;#39;): print(l[0],l[1][&amp;#39;href&amp;#39;]) #2.解析CS</description>
    </item>
    
  </channel>
</rss>